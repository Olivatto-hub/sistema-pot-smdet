import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import warnings
import re
from typing import List, Dict, Any, Tuple
warnings.filterwarnings('ignore')

# ============================================
# CONFIGURA√á√ÉO DA P√ÅGINA
# ============================================
st.set_page_config(
    page_title="Sistema POT-SMDET - Monitoramento e An√°lise",
    page_icon="üîé",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================
# CSS MINIMALISTA E COM FOCO EM UX
# ============================================
st.markdown("""
<style>
    /* MELHORIAS GERAIS - N√ÉO INTERFERE NO TEMA */
    .stDataFrame {
        border-radius: 8px;
        overflow: hidden;
    }
    
    /* MELHOR VISIBILIDADE PARA DATAFRAMES */
    .stDataFrame th {
        font-weight: 700 !important;
        text-align: center;
    }
    
    /* ESPA√áAMENTO MELHOR ENTRE WIDGETS */
    .stSlider, .stSelectbox, .stMultiSelect, .stDateInput {
        margin-bottom: 1rem;
    }
    
    /* BOT√ïES MAIS VIS√çVEIS */
    .stButton > button {
        border-radius: 8px;
        font-weight: 700;
        transition: all 0.3s ease;
        padding: 0.5rem 1rem;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }

    /* T√çTULOS DE SE√á√ÉO */
    .stMarkdown h3 {
        border-bottom: 2px solid #333; /* Uma linha para separar se√ß√µes */
        padding-bottom: 5px;
        margin-top: 20px;
    }
    
    /* INDICADORES (KPIs) */
    [data-testid="stMetricValue"] {
        font-size: 2.5rem;
        font-weight: 800;
        color: #1f77b4; /* Cor prim√°ria para destaque */
    }
    [data-testid="stMetricLabel"] {
        font-size: 1.0rem;
        font-weight: 600;
    }
    
    /* EXPANDER (Para Inconsist√™ncias) */
    .stExpander {
        border: 2px solid #ff4b4b; /* Vermelho para destaque de erro */
        border-radius: 8px;
        margin-top: 15px;
    }

</style>
""", unsafe_allow_html=True)

# ============================================
# VARI√ÅVEIS DE ESTADO
# ============================================
if 'data' not in st.session_state:
    st.session_state['data'] = pd.DataFrame()
if 'inconsistencias' not in st.session_state:
    st.session_state['inconsistencias'] = []
if 'arquivos_carregados' not in st.session_state:
    st.session_state['arquivos_carregados'] = {}

# ============================================
# FUN√á√ïES AUXILIARES
# ============================================

def formatar_moeda_brl(valor: Any) -> str:
    """Formata um valor num√©rico para o padr√£o monet√°rio brasileiro (R$ 9.999.999,99)."""
    if pd.isna(valor) or valor in ('', 'nan', 'NaT'):
        return 'R$ 0,00'
    try:
        # Tenta limpar string (remove separador de milhares americano e substitui decimal por ponto)
        if isinstance(valor, str):
            # Tenta tratar a invers√£o de nota√ß√£o americana/europeia. Prioriza BRL.
            # Se tiver mais de uma v√≠rgula ou ponto (ex: 1.000,00 ou 1,000.00), trata.
            if len(re.findall(r'[.,]', valor)) > 1:
                valor_limpo = valor.replace('.', '').replace(',', '.') # Assume padr√£o BR/EUR (1.000,00)
            else:
                valor_limpo = valor.replace(',', '.') # Assume nota√ß√£o simples 1000,00

            valor_float = float(re.sub(r'[^\d.]', '', valor_limpo))
        elif isinstance(valor, (int, float)):
            valor_float = valor
        else:
            return str(valor)

        # Formata para BRL (usando o truque de replace para trocar . por , e adicionar .)
        texto = f"{valor_float:,.2f}"
        return f"R$ {texto.replace(',', '_').replace('.', ',').replace('_', '.')}"
    except Exception as e:
        # st.error(f"Erro ao formatar valor '{valor}': {e}")
        return str(valor) # Retorna original se falhar

def limpar_colunas_monetarias(df: pd.DataFrame, colunas: List[str]) -> pd.DataFrame:
    """Limpa e converte colunas de valor para float, tratando padr√µes BRL/EUA."""
    for col in colunas:
        if col in df.columns:
            # 1. Tenta tratar strings como BRL (1.000,00) ou EUA (1,000.00)
            df[col] = df[col].astype(str).str.replace(r'[^0-9,.]', '', regex=True)
            
            # Fun√ß√£o de limpeza para aplica√ß√£o
            def clean_value(val):
                if pd.isna(val) or val in ('', 'nan', 'NaT'):
                    return np.nan
                s_val = str(val)
                # Se tiver mais de um separador (ponto e v√≠rgula), assume BRL (1.000,00)
                if s_val.count('.') > 0 and s_val.count(',') > 0:
                    s_val = s_val.replace('.', '').replace(',', '.')
                # Se tiver apenas v√≠rgula, assume separador decimal BRL (100,00)
                elif s_val.count(',') == 1 and s_val.count('.') == 0:
                    s_val = s_val.replace(',', '.')
                # Se tiver apenas ponto e for o √∫ltimo, assume separador decimal EUA (100.00)
                # Caso contr√°rio, pode ser separador de milhar.
                try:
                    return float(s_val)
                except:
                    return np.nan
            
            df[col] = df[col].apply(clean_value)
    return df

def normalizar_coluna_data(df: pd.DataFrame, coluna: str) -> pd.DataFrame:
    """Tenta converter uma coluna para datetime, tratando diferentes formatos."""
    if coluna in df.columns:
        # Lista de formatos comuns, priorizando o BR
        formatos = ['%d/%m/%Y', '%d-%m-%Y', '%Y-%m-%d', '%m/%d/%Y', '%d/%m/%y']
        
        for fmt in formatos:
            try:
                # Tenta converter o restante que n√£o foi convertido com o formato atual
                df[coluna] = pd.to_datetime(df[coluna], format=fmt, errors='coerce')
                # Se a convers√£o for bem sucedida, sai do loop
                if df[coluna].notna().sum() > 0:
                    break
            except Exception:
                continue
        
        # O que sobrar (ou seja, n√£o conseguiu converter), fica como NaT
        df[coluna] = pd.to_datetime(df[coluna], errors='coerce')
    return df

def encontrar_inconsistencias_criticas(df: pd.DataFrame, nome_arquivo: str) -> List[Dict[str, Any]]:
    """
    Identifica inconsist√™ncias cr√≠ticas de CPF repetido com dados divergentes.
    CPFs repetidos com diferentes Nomes OU diferentes N√∫meros de Cart√£o.
    """
    df_temp = df.copy()
    inconsistencias = []
    
    # Padroniza√ß√£o e Limpeza
    if 'CPF' in df_temp.columns:
        df_temp['CPF_Limpo'] = df_temp['CPF'].astype(str).str.replace(r'[^0-9]', '', regex=True).replace('', np.nan)
    else:
        return inconsistencias # Se n√£o tem CPF, n√£o verifica este tipo de erro

    for col in ['Nome', 'Num Cartao', 'NumCartao']:
        if col in df_temp.columns:
            if col.startswith('NumCartao'): # Normalizar Num Cart√£o
                df_temp[col] = df_temp[col].astype(str).str.replace(r'[^0-9]', '', regex=True).replace('', np.nan)
            elif col == 'Nome': # Normalizar Nome
                df_temp[col] = df_temp[col].astype(str).str.strip().str.upper()

    # Garantir que 'Num Cartao' exista (usando 'NumCartao' como fallback)
    if 'Num Cartao' not in df_temp.columns and 'NumCartao' in df_temp.columns:
        df_temp.rename(columns={'NumCartao': 'Num Cartao'}, inplace=True)
    
    # 1. Filtrar CPFs duplicados e v√°lidos
    df_duplicados = df_temp.dropna(subset=['CPF_Limpo']).duplicated(subset=['CPF_Limpo'], keep=False)
    df_duplicados = df_temp[df_duplicados].sort_values(by='CPF_Limpo')
    
    if df_duplicados.empty:
        return inconsistencias
        
    # Colunas chave para verifica√ß√£o
    colunas_chave = ['Nome']
    if 'Num Cartao' in df_temp.columns:
        colunas_chave.append('Num Cartao')
        
    colunas_relatorio = [c for c in ['Projeto', 'Nome', 'CPF', 'Num Cartao', 'DataPagto', 'Valor Pagto'] if c in df_temp.columns]

    # 2. Agrupar por CPF_Limpo para identificar diverg√™ncias
    for cpf_limpo, grupo in df_duplicados.groupby('CPF_Limpo'):
        is_inconsistent = False
        detalhes = []
        
        # Verifica diverg√™ncia de Nome
        if 'Nome' in grupo.columns and grupo['Nome'].nunique() > 1:
            is_inconsistent = True
            detalhes.append(f'Nomes Diferentes ({grupo["Nome"].nunique()} variantes)')
        
        # Verifica diverg√™ncia de Num Cartao
        if 'Num Cartao' in grupo.columns and grupo['Num Cartao'].nunique() > 1:
            is_inconsistent = True
            detalhes.append(f'N√∫meros de Cart√£o Diferentes ({grupo["Num Cartao"].nunique()} variantes)')

        if is_inconsistent:
            for index, row in grupo.iterrows():
                inconsistencias.append({
                    'Arquivo': nome_arquivo,
                    'Tipo Inconsist√™ncia': 'CPF Duplicado',
                    'Detalhes': ', '.join(detalhes),
                    'CPF_Limpo': cpf_limpo,
                    'Registro': {col: row.get(col, 'N/A') for col in colunas_relatorio}
                })

    return inconsistencias

@st.cache_data(show_spinner="Analisando dados e inconsist√™ncias...")
def processar_e_analisar_dados(uploaded_files: List[st.runtime.uploaded_file_manager.UploadedFile]) -> Tuple[pd.DataFrame, List[Dict[str, Any]], Dict[str, str]]:
    """Carrega, limpa, padroniza e analisa todos os arquivos carregados."""
    todos_dados = []
    todas_inconsistencias = []
    
    # Mapeamento para padronizar nomes de colunas (caso haja varia√ß√µes)
    coluna_map_valores = {
        'valortotal': 'Valor Total',
        'valordesconto': 'Valor Desconto',
        'valorpagto': 'Valor Pagto',
        'valordia': 'Valor Dia',
        'data pagto': 'DataPagto',
        'num cartao': 'Num Cartao',
        'numcartao': 'Num Cartao',
        'data pagto': 'DataPagto',
        'cpf': 'CPF',
        'nome': 'Nome',
        'projeto': 'Projeto',
    }

    arquivos_info = {}

    for file in uploaded_files:
        try:
            # 1. Leitura do arquivo
            if file.name.lower().endswith('.csv'):
                df = pd.read_csv(file, sep=';', encoding='latin1', skip_blank_lines=True)
            elif file.name.lower().endswith('.txt'):
                df = pd.read_csv(file, sep='\t', encoding='latin1', skip_blank_lines=True)
            else:
                st.warning(f"Formato de arquivo n√£o suportado para {file.name}. Ignorando.")
                continue

            # 2. Limpeza e Padroniza√ß√£o de Colunas
            df.columns = df.columns.str.strip().str.lower().str.replace('[^a-z0-9]', '', regex=True)
            df.rename(columns=lambda c: coluna_map_valores.get(c, c), inplace=True)
            
            # Limpa colunas que s√≥ cont√™m valores vazios/nulos
            df.dropna(axis=1, how='all', inplace=True)
            df.dropna(axis=0, how='all', inplace=True)
            
            # 3. Tratamento de Tipos
            colunas_monetarias = ['Valor Total', 'Valor Desconto', 'Valor Pagto', 'Valor Dia']
            df = limpar_colunas_monetarias(df, colunas_monetarias)
            
            # 4. Normaliza√ß√£o de Datas
            df = normalizar_coluna_data(df, 'DataPagto')
            
            # 5. An√°lise de Inconsist√™ncias
            inconsistencias_do_arquivo = encontrar_inconsistencias_criticas(df, file.name)
            todas_inconsistencias.extend(inconsistencias_do_arquivo)
            
            # Adicionar coluna de origem e metadados
            df['Arquivo_Origem'] = file.name
            df['Mes_Ano'] = df['DataPagto'].dt.strftime('%Y-%m') if 'DataPagto' in df.columns else 'N/A'

            todos_dados.append(df)
            arquivos_info[file.name] = "OK"

        except Exception as e:
            st.error(f"‚ùå Erro ao processar o arquivo '{file.name}': {e}")
            arquivos_info[file.name] = f"Erro: {e}"
            continue

    if not todos_dados:
        return pd.DataFrame(), [], arquivos_info

    # Combina todos os DataFrames
    df_final = pd.concat(todos_dados, ignore_index=True)
    
    # Garante colunas m√≠nimas e preenche NaN se necess√°rio (importante para evitar falhas em colunas ausentes)
    colunas_padrao = ['Projeto', 'Nome', 'Num Cartao', 'CPF', 'DataPagto', 'Valor Pagto', 'Arquivo_Origem', 'Mes_Ano']
    for col in colunas_padrao:
        if col not in df_final.columns:
            df_final[col] = np.nan
    
    # Remove NaN da coluna de data para evitar problemas no filtro
    df_final.dropna(subset=['DataPagto'], inplace=True)
    
    return df_final, todas_inconsistencias, arquivos_info

# ============================================
# LAYOUT DA BARRA LATERAL (FILTROS)
# ============================================

with st.sidebar:
    st.title("‚öôÔ∏è Controles e Filtros")
    
    uploaded_files = st.file_uploader(
        "üìÇ Carregar Arquivos de Dados (.csv, .txt)",
        type=['csv', 'txt'],
        accept_multiple_files=True
    )
    
    if uploaded_files:
        st.subheader("Processamento de Dados")
        # For√ßa o reprocessamento se os arquivos mudarem ou o bot√£o for clicado
        if st.button("üîÑ Processar Novamente"):
            st.session_state['data'], st.session_state['inconsistencias'], st.session_state['arquivos_carregados'] = processar_e_analisar_dados(uploaded_files)
        
        # Carrega/recarrega os dados na sess√£o
        if not st.session_state['data'].empty or len(uploaded_files) != len(st.session_state['arquivos_carregados']):
            st.session_state['data'], st.session_state['inconsistencias'], st.session_state['arquivos_carregados'] = processar_e_analisar_dados(uploaded_files)

        df_original = st.session_state['data']
        
        if not df_original.empty:
            
            # ----------------------------------------------------
            # 1. FILTROS DE PROJETO E ARQUIVO
            # ----------------------------------------------------
            st.markdown("### üè∑Ô∏è Filtros de Contexto")
            
            # Filtro de Arquivo
            arquivos_unicos = ['TODOS'] + sorted(df_original['Arquivo_Origem'].unique().tolist())
            arquivo_selecionado = st.selectbox(
                "Filtrar por Arquivo:",
                arquivos_unicos
            )
            
            # Filtro de Projeto
            projetos_unicos = ['TODOS'] + sorted(df_original['Projeto'].astype(str).str.strip().unique().tolist())
            projeto_selecionado = st.selectbox(
                "Filtrar por Projeto:",
                projetos_unicos
            )
            
            # ----------------------------------------------------
            # 2. FILTROS DE PER√çODO (NOVIDADE)
            # ----------------------------------------------------
            st.markdown("### üìÖ Filtros de Per√≠odo")

            tipo_filtro_data = st.radio(
                "Escolha o Tipo de Filtro:",
                ('Per√≠odo Espec√≠fico', 'M√™s e Ano'),
                key='tipo_filtro_data'
            )

            df_filtrado = df_original.copy()
            
            if tipo_filtro_data == 'Per√≠odo Espec√≠fico':
                col_d_start, col_d_end = st.columns(2)
                
                # Encontrar a data m√≠nima e m√°xima no conjunto de dados
                min_date = df_original['DataPagto'].min()
                max_date = df_original['DataPagto'].max()
                
                with col_d_start:
                    data_inicio = st.date_input(
                        "Data In√≠cio:",
                        value=min_date,
                        min_value=min_date,
                        max_value=max_date,
                        key='data_inicio'
                    )
                
                with col_d_end:
                    data_fim = st.date_input(
                        "Data Fim:",
                        value=max_date,
                        min_value=min_date,
                        max_value=max_date,
                        key='data_fim'
                    )
                
                # Aplicar filtro de per√≠odo
                if data_inicio and data_fim:
                    df_filtrado = df_filtrado[
                        (df_filtrado['DataPagto'].dt.date >= data_inicio) & 
                        (df_filtrado['DataPagto'].dt.date <= data_fim)
                    ]

            elif tipo_filtro_data == 'M√™s e Ano':
                col_m, col_a = st.columns(2)
                
                # Obter meses e anos √∫nicos do Mes_Ano
                meses_anos_disponiveis = sorted(df_original['Mes_Ano'].unique().tolist())
                mes_ano_selecionado = st.selectbox(
                    "Selecione o M√™s/Ano:",
                    ['TODOS'] + meses_anos_disponiveis,
                    key='mes_ano_selecionado'
                )

                if mes_ano_selecionado != 'TODOS':
                    df_filtrado = df_filtrado[df_filtrado['Mes_Ano'] == mes_ano_selecionado]

            # Aplica filtros de Arquivo e Projeto ao DF filtrado por data
            if arquivo_selecionado != 'TODOS':
                df_filtrado = df_filtrado[df_filtrado['Arquivo_Origem'] == arquivo_selecionado]
            
            if projeto_selecionado != 'TODOS':
                df_filtrado = df_filtrado[df_filtrado['Projeto'] == projeto_selecionado]

            # Armazena o DataFrame filtrado para uso no Main Content
            st.session_state['df_filtrado'] = df_filtrado
            
            # Exibir resumo dos arquivos processados
            st.markdown("---")
            st.markdown("#### Status dos Arquivos")
            for arquivo, status in st.session_state['arquivos_carregados'].items():
                icon = "‚úÖ" if status == "OK" else "‚ùå"
                st.caption(f"{icon} **{arquivo}**: {status}")

        else:
            st.warning("Aguardando o carregamento e processamento dos dados.")
            st.session_state['df_filtrado'] = pd.DataFrame() # Garante que o df filtrado est√° vazio

    else:
        st.session_state['df_filtrado'] = pd.DataFrame()
        st.session_state['data'] = pd.DataFrame()
        st.session_state['inconsistencias'] = []


# ============================================
# LAYOUT PRINCIPAL (CONTE√öDO)
# ============================================

st.title("Sistema de An√°lise e Monitoramento de Projetos")

df_filtrado = st.session_state.get('df_filtrado', pd.DataFrame())
todas_inconsistencias = st.session_state.get('inconsistencias', [])

if df_filtrado.empty:
    st.info("Carregue e processe um ou mais arquivos na barra lateral para iniciar a an√°lise.")
else:
    # ----------------------------------------------------
    # ABAS DE NAVEGA√á√ÉO
    # ----------------------------------------------------
    tab_analise, tab_inconsistencias, tab_dados, tab_config = st.tabs(
        [
            "üìä An√°lise Geral", 
            f"üö® Inconsist√™ncias Cr√≠ticas ({len(todas_inconsistencias)})", 
            "üìù Dados Detalhados", 
            "‚öôÔ∏è Configura√ß√µes"
        ]
    )

    # ============================================
    # ABA 1: AN√ÅLISE GERAL
    # ============================================
    with tab_analise:
        st.header("Resumo Financeiro e Distribui√ß√£o")
        
        # 1. KPIs
        df_kpi = df_filtrado.copy()
        
        # Calcula KPIs ap√≥s a filtragem
        total_pago = df_kpi['Valor Pagto'].sum() if 'Valor Pagto' in df_kpi.columns else 0
        total_registros = len(df_kpi)
        projetos_ativos = df_kpi['Projeto'].nunique() if 'Projeto' in df_kpi.columns else 0
        
        col_k1, col_k2, col_k3, col_k4 = st.columns(4)
        
        with col_k1:
            st.metric("Total Pago (Per√≠odo Filtrado)", formatar_moeda_brl(total_pago))
        with col_k2:
            st.metric("Total de Registros", total_registros)
        with col_k3:
            st.metric("Projetos Envolvidos", projetos_ativos)
        with col_k4:
            media_pagto = total_pago / total_registros if total_registros > 0 else 0
            st.metric("M√©dia por Registro", formatar_moeda_brl(media_pagto))
            
        st.markdown("---")

        # 2. GR√ÅFICOS
        if 'Valor Pagto' in df_kpi.columns and 'Projeto' in df_kpi.columns:
            st.subheader("Distribui√ß√£o do Valor Pago por Projeto")
            
            # Agrupamento de dados para o gr√°fico
            df_projeto = df_kpi.groupby('Projeto')['Valor Pagto'].sum().reset_index()
            df_projeto['Valor Pagto Formatado'] = df_projeto['Valor Pagto'].apply(formatar_moeda_brl)
            
            fig_proj = px.bar(
                df_projeto.sort_values(by='Valor Pagto', ascending=False),
                x='Projeto',
                y='Valor Pagto',
                text='Valor Pagto Formatado',
                title='Soma Total de Pagamentos por Projeto',
                color='Projeto',
                template='plotly_white'
            )
            fig_proj.update_traces(textposition='outside')
            fig_proj.update_layout(showlegend=False, yaxis_title="Valor Pago (R$)", xaxis_title="Projeto")
            st.plotly_chart(fig_proj, use_container_width=True)

        if 'DataPagto' in df_kpi.columns and 'Valor Pagto' in df_kpi.columns:
            st.subheader("Evolu√ß√£o Mensal do Pagamento")
            
            df_mensal = df_kpi.set_index('DataPagto').resample('M')['Valor Pagto'].sum().reset_index()
            df_mensal['Mes_Ano'] = df_mensal['DataPagto'].dt.strftime('%Y-%m')
            
            fig_time = px.line(
                df_mensal,
                x='Mes_Ano',
                y='Valor Pagto',
                markers=True,
                title='S√©rie Hist√≥rica do Pagamento Mensal',
                template='plotly_white'
            )
            fig_time.update_layout(xaxis_title="M√™s/Ano", yaxis_title="Valor Pago (R$)")
            st.plotly_chart(fig_time, use_container_width=True)


    # ============================================
    # ABA 2: INCONSIST√äNCIAS CR√çTICAS (NOVIDADE)
    # ============================================
    with tab_inconsistencias:
        st.header("üö® Inconsist√™ncias Cr√≠ticas Detectadas")
        
        if todas_inconsistencias:
            st.warning(f"Foram encontradas **{len(todas_inconsistencias)}** inconsist√™ncias que requerem aten√ß√£o da equipe.")
            
            # Convers√£o da lista de dicion√°rios de inconsist√™ncias para DataFrame para exibi√ß√£o
            # Transformamos os dados aninhados para exibi√ß√£o plana
            dados_inconsistentes = []
            for inc in todas_inconsistencias:
                registro = inc['Registro']
                dados_inconsistentes.append({
                    'Arquivo Origem': inc['Arquivo'],
                    'Tipo': inc['Tipo Inconsist√™ncia'],
                    'Detalhes do Erro': inc['Detalhes'],
                    'CPF Duplicado': inc['CPF_Limpo'],
                    'Nome no Registro': registro.get('Nome', 'N/A'),
                    'Cart√£o no Registro': registro.get('Num Cartao', 'N/A'),
                    'Projeto': registro.get('Projeto', 'N/A'),
                    'Data Pagto': registro.get('DataPagto', 'N/A'),
                    'Valor Pagto': formatar_moeda_brl(registro.get('Valor Pagto', 0)),
                })
            
            df_inconsistencias = pd.DataFrame(dados_inconsistentes)
            
            st.markdown("### Tabela de Registros Inconsistentes")
            st.caption("Filtre o DataFrame abaixo para priorizar as a√ß√µes de corre√ß√£o. **Os valores monet√°rios est√£o no padr√£o BRL.**")
            
            # Exibe a tabela de inconsist√™ncias com filtro e formata√ß√£o
            st.dataframe(
                df_inconsistencias,
                use_container_width=True,
                height=500
            )

            # Exporta√ß√£o do relat√≥rio de inconsist√™ncias (A√ß√£o Imediata)
            csv_inconsistencias = df_inconsistencias.to_csv(index=False, sep=';', encoding='utf-8-sig')
            st.download_button(
                label="üì• Exportar Relat√≥rio de Inconsist√™ncias (CSV)",
                data=csv_inconsistencias,
                file_name=f"RELATORIO_INCONSISTENCIAS_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime='text/csv',
                type="secondary"
            )

        else:
            st.success("üéâ N√£o foram encontradas inconsist√™ncias cr√≠ticas (CPFs repetidos com dados divergentes) no conjunto de dados filtrado.")

    # ============================================
    # ABA 3: DADOS DETALHADOS
    # ============================================
    with tab_dados:
        st.header("Visualiza√ß√£o e Detalhamento dos Dados")
        
        st.caption(f"Exibindo {len(df_filtrado)} registros (ap√≥s filtros de per√≠odo e contexto).")
        
        # Prepara a visualiza√ß√£o: aplica a formata√ß√£o BRL
        df_display = df_filtrado.copy()
        
        colunas_monetarias = ['Valor Total', 'Valor Desconto', 'Valor Pagto', 'Valor Dia']
        for col in colunas_monetarias:
            if col in df_display.columns:
                df_display[col] = df_display[col].apply(formatar_moeda_brl)
                
        # Formata a data para BR
        if 'DataPagto' in df_display.columns:
            df_display['DataPagto'] = df_display['DataPagto'].dt.strftime('%d/%m/%Y')
        
        st.dataframe(
            df_display, 
            use_container_width=True,
            height=600
        )

    # ============================================
    # ABA 4: CONFIGURA√á√ïES E EXPORTA√á√ÉO
    # ============================================
    with tab_config:
        st.header("Op√ß√µes do Sistema e Exporta√ß√£o de Relat√≥rios")

        # ----------------------------------------------------
        # SIMULA√á√ÉO DE EXPORTA√á√ÉO AVAN√áADA
        # ----------------------------------------------------
        st.markdown("### üíæ OP√á√ïES DE EXPORTA√á√ÉO DE RELAT√ìRIOS")
        st.markdown("""
        **Aviso:** O relat√≥rio exportado incluir√°:
        1.  O resumo da **An√°lise Geral** (KPIs e Gr√°ficos).
        2.  A lista completa de **Inconsist√™ncias Cr√≠ticas** (com o nome do arquivo original e informa√ß√µes do registro).
        3.  Os **Dados Detalhados** do per√≠odo e contexto filtrados.
        """)

        col_e1, col_e2 = st.columns(2)
        
        with col_e1:
            formato_exportacao = st.selectbox(
                "Formato padr√£o de exporta√ß√£o:",
                ["PDF (Recomendado)", "Excel (.xlsx)", "CSV (.csv)"]
            )
        
        with col_e2:
            incluir_graficos = st.checkbox(
                "Incluir gr√°ficos nos relat√≥rios",
                value=True
            )
        
        st.button("‚öôÔ∏è GERAR RELAT√ìRIO (EMULA√á√ÉO)", type="primary", use_container_width=True)
        
        if formato_exportacao == "PDF (Recomendado)":
            st.info("A gera√ß√£o de PDF com inclus√£o de inconsist√™ncias e metadados foi solicitada e ser√° integrada na pr√≥xima atualiza√ß√£o do sistema.")
        
        # Bot√£o real de exporta√ß√£o para CSV/Excel do DF Filtrado (somente para dados limpos, n√£o o relat√≥rio complexo)
        
        def to_excel(df):
            output = BytesIO()
            writer = pd.ExcelWriter(output, engine='xlsxwriter')
            df.to_excel(writer, index=False, sheet_name='Dados Filtrados')
            writer.close()
            return output.getvalue()
        
        # Prepara o DF para exporta√ß√£o (voltando a nota√ß√£o num√©rica padr√£o para software)
        df_export_num = df_filtrado.copy()
        for col in ['Valor Total', 'Valor Desconto', 'Valor Pagto', 'Valor Dia']:
            if col in df_export_num.columns:
                # Remove a formata√ß√£o BRL para que o software que ler o arquivo reconhe√ßa o n√∫mero
                df_export_num[col] = pd.to_numeric(df_export_num[col], errors='coerce')

        st.download_button(
            label="üì• Exportar Dados Filtrados para Excel (.xlsx)",
            data=to_excel(df_export_num),
            file_name=f"DADOS_FILTRADOS_{datetime.now().strftime('%Y%m%d')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="download_excel"
        )


        # ----------------------------------------------------
        # OP√á√ïES DO SISTEMA (MANTIDAS DO C√ìDIGO ANTERIOR)
        # ----------------------------------------------------
        st.markdown("### üñ•Ô∏è OP√á√ïES DE VALIDA√á√ÉO")
        
        col_s1, col_s2 = st.columns(2)
        with col_s1:
            auto_validar = st.checkbox(
                "Valida√ß√£o autom√°tica ao carregar",
                value=True,
                help="Executa valida√ß√£o autom√°tica ap√≥s carregar dados"
            )
            
            manter_historico = st.checkbox(
                "Manter hist√≥rico de altera√ß√µes",
                value=True,
                help="Armazena hist√≥rico de modifica√ß√µes nos dados"
            )
        
        with col_s2:
            limite_registros = st.number_input(
                "Limite de registros para processamento:",
                min_value=1000,
                max_value=1000000,
                value=100000,
                step=1000,
                help="Define o n√∫mero m√°ximo de registros para processamento otimizado"
            )
        
        # Bot√£o para salvar configura√ß√µes
        if st.button("üíæ SALVAR CONFIGURA√á√ïES", type="secondary", use_container_width=True):
            st.success("‚úÖ Configura√ß√µes salvas com sucesso!")
            # Aqui voc√™ implementaria a l√≥gica para salvar as configura√ß√µes
            
# ============================================
# FIM DO C√ìDIGO
# ============================================
